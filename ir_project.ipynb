{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XeyxTL7yvo-_",
    "outputId": "17d97af2-ed76-4814-e448-5de99907f661"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm \n",
    "import nltk\n",
    "import itertools\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Blefm5rxv0Sx",
    "outputId": "6c29b5b0-4b7b-4399-81db-10e3b0efd5b4"
   },
   "outputs": [],
   "source": [
    "def getDocs(path):\n",
    "    numberOfDocs = 0\n",
    "    Docs = {}\n",
    "    for file in tqdm(os.listdir(path)):\n",
    "          f_path = os.path.join(path, file)\n",
    "          f_open = open(f_path, \"r\")\n",
    "          index = file.split(\"/\")[-1].split(\".\")[0] \n",
    "          Docs[int(index)] = f_open.read()\n",
    "          numberOfDocs += 1  \n",
    "    Docs = dict(sorted(Docs.items()))\n",
    "    return Docs,numberOfDocs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jpmd7qyZx7-L",
    "outputId": "de760f48-0710-4fc6-c765-6a86cfb78b3d"
   },
   "outputs": [],
   "source": [
    "def getWordsTokenize(sentences):\n",
    "    words = []\n",
    "    for word_data in sentences:\n",
    "      words += word_data.split()\n",
    "    return words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove StopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8JEeQJ4BA3UK",
    "outputId": "53df230f-2c6d-449e-c58c-5987229fa1de"
   },
   "outputs": [],
   "source": [
    "def getWordsStopWords(words):\n",
    "    en_stops = set(stopwords.words('english'))\n",
    "    en_stops.remove('in')\n",
    "    en_stops.remove('to')\n",
    "    en_stops.remove('where')\n",
    "    stopWords = []\n",
    "    for word in words:\n",
    "        if word not in en_stops:\n",
    "          stopWords.append(word)\n",
    "    return stopWords\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Duplicates Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeDuplicates(x):\n",
    "  return list(dict.fromkeys(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### builds the positional index matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iuVo8xBVN3aa",
    "outputId": "bdc115f9-35ad-4728-b542-8fcaa5db98f9"
   },
   "outputs": [],
   "source": [
    "def positionalIndex(words,d_Docs):    \n",
    "    positional_index = {}\n",
    "    \n",
    "    for word in words:\n",
    "        for doc,words in d_Docs.items():\n",
    "            index = 0\n",
    "            for word_in_file in words:\n",
    "                index += 1\n",
    "                # index is the position of word in file\n",
    "                if word == word_in_file:\n",
    "                    if (len(positional_index) == 0):\n",
    "                        positional_index[word] = {'Doc'+str(doc): [index]}\n",
    "                    else:\n",
    "                        if word in positional_index:\n",
    "                            if 'Doc'+str(doc) in positional_index[word]:\n",
    "                                positional_index[word]['Doc'+str(doc)].append(index)\n",
    "                            else:\n",
    "                                positional_index[word]['Doc'+str(doc)] = [index]\n",
    "                                \n",
    "                        else:\n",
    "                            positional_index[word] = {'Doc'+str(doc): [index]}\n",
    "                            \n",
    "    for key,values in positional_index.items():\n",
    "        positional_index.update({key : [len(values) , values]})\n",
    "    return positional_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### search index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_index(query, positional_index):\n",
    "\n",
    "    matched_docs_sets = []\n",
    "\n",
    "    if len(query) == 1:\n",
    "        \n",
    "        if query[0] in positional_index:\n",
    "            result = [key for key in positional_index[query[0]][1]]\n",
    "        else:\n",
    "            result = []\n",
    "\n",
    "        return result\n",
    "    \n",
    "    else:\n",
    "\n",
    "        for i in range(len(query)-1):\n",
    "            matched_docs = []\n",
    "            if query[i] in positional_index:\n",
    "                first_docs = positional_index[query[i]][1]\n",
    "                if query[i+1] in positional_index:\n",
    "                    second_docs = positional_index[query[i+1]][1]\n",
    "                    for doc in first_docs:\n",
    "                        if doc in second_docs:\n",
    "                            for pos in first_docs[doc]:\n",
    "                                if pos + 1 in second_docs[doc]:\n",
    "                                    matched_docs.append(doc)\n",
    "                else:\n",
    "                    break\n",
    "            else:\n",
    "                break\n",
    "\n",
    "            if matched_docs:\n",
    "                matched_docs_sets.append(set(matched_docs))\n",
    "            else:\n",
    "                result = []\n",
    "                return result\n",
    "    if matched_docs_sets:\n",
    "        result = set.intersection(*matched_docs_sets)\n",
    "    else:\n",
    "        return []\n",
    "    return list(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### builds the TF and w tf(1+ log tf) matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calc_wtf(tf):\n",
    "    tf = 1 + math.log10(tf)\n",
    "    return tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tf_wtf_matrix(positional_index,N):\n",
    "    tf_= {} \n",
    "    wtf_ = {}\n",
    "    for term in positional_index:\n",
    "        for i in range(N):\n",
    "            if 'Doc'+str(i+1) in positional_index[term][1]:\n",
    "                if term not in tf_:\n",
    "                    tf_[term] = {'Doc'+str(i+1) : len(positional_index[term][1]['Doc'+str(i+1)])}\n",
    "                    wtf_[term] = {'Doc'+str(i+1) : calc_wtf(tf_[term]['Doc'+str(i+1)])}\n",
    "                else :\n",
    "                    tf_[term]['Doc'+str(i+1)] = len(positional_index[term][1]['Doc'+str(i+1)])\n",
    "                    wtf_[term]['Doc'+str(i+1)] = calc_wtf(tf_[term]['Doc'+str(i+1)])\n",
    "            else :\n",
    "                if term not in tf_:\n",
    "                    tf_[term] = {'Doc'+str(i+1) : 0}\n",
    "                    wtf_[term] = {'Doc'+str(i+1) : 0.0}\n",
    "                else :\n",
    "                    tf_[term]['Doc'+str(i+1)] = 0\n",
    "                    wtf_[term]['Doc'+str(i+1)] = 0.0\n",
    "\n",
    "    return tf_,wtf_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### builds the df and idf matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_df_idf_matrix(positional_index, N):\n",
    "    df_idf = {}\n",
    "    for term , value in positional_index.items():\n",
    "        df_idf[term] = {'df' : value[0]}\n",
    "        df_idf[term]['idf'] = round(math.log10(N / value[0]),10)\n",
    "    \n",
    "    return df_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### builds the tf.idf matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_tfidf(tf_, idf):\n",
    "\n",
    "    tfidf = [round(element * idf, 10) for element in tf_.values()]\n",
    "    \n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tfidf_matrix(positional_index,wtf,idf, N):\n",
    "    \n",
    "    tfidf_matrix = {}\n",
    "    for term in positional_index:\n",
    "        tfidf = calc_tfidf(wtf[term], idf[term]['idf'])\n",
    "        tfidf_matrix[term] = tfidf\n",
    "\n",
    "    return tfidf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculating documents lengths to be used for normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_doc_length(tfidf_matrix, N):\n",
    "\n",
    "    doc_length = [0.0] * N\n",
    "    for term in tfidf_matrix:\n",
    "        doc_length = np.add(doc_length, [math.pow(element, 2) for element in tfidf_matrix[term]])\n",
    "        \n",
    "    \n",
    "    doc_length = [round(math.sqrt(element),9) for element in doc_length]\n",
    "\n",
    "    return doc_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_terms(tfidf_matrix, doc_length):\n",
    "    normalized_matrix = {}\n",
    "    for term in tfidf_matrix:\n",
    "        normalized_matrix[term] = []\n",
    "        i = 0\n",
    "        for element in tfidf_matrix[term]:\n",
    "            normalized_matrix[term].append(round((element / doc_length[i]), 10))\n",
    "            i = i + 1\n",
    "    return normalized_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prints the positional index, the tf.idf matrix normalized matrix, TF matrix, WTF matrix, df_idf and doc_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareToPrint(Dict):\n",
    "    listof = []\n",
    "    if type(Dict) is dict:\n",
    "        listofkey = list(Dict.keys())\n",
    "        listofvalue = list(Dict.values())\n",
    "        l = [0]\n",
    "        l2 = [0]\n",
    "        for i in range(len(listofkey)):\n",
    "            l [0] = listofkey[i]\n",
    "            if type(listofvalue[0]) is dict:\n",
    "                listof.append(l+ list(listofvalue[i].values()))\n",
    "            elif type(listofvalue[0]) is list:\n",
    "                listof.append(l+ listofvalue[i])\n",
    "            else:\n",
    "                l2[0] = listofvalue[i]\n",
    "                listof.append(l+ l2)\n",
    "    else :\n",
    "        l1 = [0]\n",
    "        l2 = [0]\n",
    "        for i in range(len(Dict)):\n",
    "            l1[0] = 'Doc'+str(i+1)\n",
    "            l2[0] = Dict[i]\n",
    "            listof.append(l1+ l2)\n",
    "    return listof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_data(positionalindex, tfidf_matrix, normalized_terms, TF, WTF, df_idf, doc_lengths, N):\n",
    "    print(\"Positional Index\")\n",
    "    print(\"\")\n",
    "    for term in positionalindex:\n",
    "        print(term, positionalindex[term])\n",
    "    print(\"----------------------------------------\")\n",
    "    print(\"TF Matrix\")\n",
    "    print(\"\")\n",
    "    print(tabulate(prepareToPrint(TF), headers=[\" \",\"Doc1\",\"Doc2\",\"Doc3\",\"Doc4\",\"Doc5\",\"Doc6\",\"Doc7\",\"Doc8\",\"Doc9\",\"Doc10\"]))\n",
    "    print(\"----------------------------------------\")\n",
    "    print(\"w tf(1+ log tf) Matrix\")\n",
    "    print(\"\")\n",
    "    print(tabulate(prepareToPrint(WTF), headers=[\" \",\"Doc1\",\"Doc2\",\"Doc3\",\"Doc4\",\"Doc5\",\"Doc6\",\"Doc7\",\"Doc8\",\"Doc9\",\"Doc10\"]))\n",
    "    print(\"----------------------------------------\")\n",
    "    print(\"df & idf Matrix\")\n",
    "    print(\"\")\n",
    "    print(tabulate(prepareToPrint(df_idf), headers=[\" \",\"df\",\"idf\"]))\n",
    "    print(\"----------------------------------------\")\n",
    "    print(\"TF.IDF Matrix\")\n",
    "    print(\"\")\n",
    "    print(tabulate(prepareToPrint(tfidf_matrix), headers=[\" \",\"Doc1\",\"Doc2\",\"Doc3\",\"Doc4\",\"Doc5\",\"Doc6\",\"Doc7\",\"Doc8\",\"Doc9\",\"Doc10\"]))\n",
    "    print(\"----------------------------------------\")\n",
    "    print(\"Docs length Matrix\")\n",
    "    print(\"\")\n",
    "    print(tabulate(prepareToPrint(doc_lengths), headers=[\" \",\"length\"]))\n",
    "    print(\"----------------------------------------\")\n",
    "    print(\"Normalized tf.id\")\n",
    "    print(\"\")\n",
    "    print(tabulate(prepareToPrint(normalized_terms), headers=[\" \",\"Doc1\",\"Doc2\",\"Doc3\",\"Doc4\",\"Doc5\",\"Doc6\",\"Doc7\",\"Doc8\",\"Doc9\",\"Doc10\"]))\n",
    "    print(\"----------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### query calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_rtf(token_list):\n",
    "\n",
    "    rtf = {}\n",
    "    for token in token_list:\n",
    "        if token in rtf:\n",
    "            rtf[token] += 1\n",
    "        else:\n",
    "            rtf[token] = 1\n",
    "    return rtf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_tf(rtf):\n",
    "\n",
    "    tf = {}\n",
    "    for token in rtf:\n",
    "        tf[token] = calc_wtf(rtf[token])\n",
    "    return tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_idf(df, N):\n",
    "\n",
    "    idf = math.log10(N / df)\n",
    "    return idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_tfidf(qtf, pos_index, N):\n",
    "\n",
    "    tfidf = {}\n",
    "    idf = {}\n",
    "    for term in qtf:\n",
    "        if term in pos_index:\n",
    "            idf[term] = query_idf(pos_index[term][0], N)\n",
    "        else:\n",
    "            idf[term] = 0\n",
    "        tfidf[term] = round(idf[term] * qtf[term], 10)\n",
    "    return tfidf,idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_length(q_tfidf):\n",
    "\n",
    "    length = 0.0\n",
    "    for term in q_tfidf:\n",
    "        length += math.pow(q_tfidf[term], 2)\n",
    "    length = math.sqrt(length)\n",
    "    return length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_normalize(length, q_tfidf):\n",
    "\n",
    "    q_normalized = {}\n",
    "    for term in q_tfidf:\n",
    "        if length == 0:\n",
    "            q_normalized[term] = 0\n",
    "        else:\n",
    "            q_normalized[term] = q_tfidf[term] / length\n",
    "    return q_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_normalize(doc_no, doc_lengths, tfidf_matrix, token_list):\n",
    "\n",
    "    doc_normalized = {}\n",
    "    for token in token_list:\n",
    "        if token in tfidf_matrix:\n",
    "            doc_normalized[token] = tfidf_matrix[token][int(doc_no[-1])-1] / doc_lengths[int(doc_no[-1])-1]\n",
    "        else:\n",
    "            doc_normalized[token] = 0\n",
    "    return doc_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### applying our calculations to the query, positional index needed for idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_processing(query, positional_index, N):\n",
    "\n",
    "    token_list = getWordsStopWords(getWordsTokenize([query.lower()]))\n",
    "    rtf = query_rtf(token_list)\n",
    "    tf = query_tf(rtf)\n",
    "    tfidf,idf = query_tfidf(tf, positional_index, N)\n",
    "    length = query_length(tfidf)\n",
    "    query_normalized = query_normalize(length, tfidf)\n",
    "    return token_list, query_normalized,rtf,tf,length,tfidf,idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculates document score using normalized weights for terms in query and document collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_score(q_normalized, d_normalized):\n",
    "\n",
    "    score = 0.0\n",
    "    product ={}\n",
    "    i = 1\n",
    "    for term in q_normalized:\n",
    "        score += q_normalized[term] * d_normalized[term]\n",
    "        product[term] = q_normalized[term] * d_normalized[term]\n",
    "        if i == len(q_normalized):\n",
    "            product['SUM'] = score\n",
    "        i += 1\n",
    "    return score, product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utilizing everything we built to return the matched documents, ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engine(query, positional_index, tfidf_matrix, doc_lengths, N):\n",
    "    docs = {}\n",
    "    product = {}\n",
    "    token_list, query_normalized,rtf,tf,length,tfidf,idf= query_processing(query, positional_index, N)\n",
    "    matched_docs = search_index(token_list, positional_index)\n",
    "    for i in range(len(matched_docs)):\n",
    "        doc_normalized = doc_normalize(matched_docs[i], doc_lengths, tfidf_matrix, token_list)\n",
    "        docs[matched_docs[i]],product[matched_docs[i]] = doc_score(query_normalized, doc_normalized)\n",
    "    \n",
    "    ranked_results = {}\n",
    "    product_results = {}\n",
    "    sorted_keys_docs = dict(sorted(docs.items(), key=lambda x:x[1], reverse=True))\n",
    "    sorted_keys_prod = sorted(product)\n",
    "    \n",
    "    for key in sorted_keys_docs:\n",
    "        ranked_results[key] = docs[key]\n",
    "        \n",
    "    for key in sorted_keys_prod:\n",
    "        product_results[key] = product[key]\n",
    "        \n",
    "    if ranked_results == {}:\n",
    "        return {}\n",
    "    else:\n",
    "        return ranked_results, query_normalized, rtf,tf, length, tfidf, idf, product_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 1667.91it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'E:/level 4/Material 4th Level/IR/project/project_test'\n",
    "d_doc,numberOfDocs = getDocs(path)\n",
    "d_Doc = {}\n",
    "for key,val in d_doc.items():\n",
    "    value = []\n",
    "    value.append(val)\n",
    "    d_Doc[key] = getWordsTokenize(value)\n",
    "d_Doc\n",
    "words = list(d_doc.values())\n",
    "words = getWordsTokenize(words)\n",
    "words = getWordsStopWords(words)\n",
    "words = removeDuplicates(words)\n",
    "numberOfDocs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initializes the necessary structures to perform multiple searches later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "positional_index = positionalIndex(words,d_Doc)\n",
    "tf_,wtf = build_tf_wtf_matrix(positional_index,numberOfDocs) \n",
    "df_idf = build_df_idf_matrix(positional_index,numberOfDocs)\n",
    "tfidf_matrix = build_tfidf_matrix(positional_index,wtf,df_idf, numberOfDocs)\n",
    "doc_lengths = calc_doc_length(tfidf_matrix, numberOfDocs)\n",
    "normalized_terms = normalize_terms(tfidf_matrix, doc_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'antony': [3, {'Doc1': [1], 'Doc2': [1], 'Doc6': [1]}],\n",
       " 'brutus': [3, {'Doc1': [2], 'Doc2': [2], 'Doc4': [1]}],\n",
       " 'caeser': [5,\n",
       "  {'Doc1': [3], 'Doc2': [3], 'Doc4': [2], 'Doc5': [1], 'Doc6': [2]}],\n",
       " 'cleopatra': [1, {'Doc1': [4]}],\n",
       " 'mercy': [5,\n",
       "  {'Doc1': [5], 'Doc3': [1], 'Doc4': [3], 'Doc5': [2], 'Doc6': [3]}],\n",
       " 'worser': [4, {'Doc1': [6], 'Doc3': [2], 'Doc4': [4], 'Doc5': [3]}],\n",
       " 'calpurnia': [1, {'Doc2': [4]}],\n",
       " 'angels': [3, {'Doc7': [1], 'Doc8': [1], 'Doc9': [1]}],\n",
       " 'fools': [4, {'Doc7': [2], 'Doc8': [2], 'Doc9': [2], 'Doc10': [1]}],\n",
       " 'fear': [3, {'Doc7': [3], 'Doc8': [3], 'Doc10': [2]}],\n",
       " 'in': [4, {'Doc7': [4], 'Doc8': [4], 'Doc9': [3], 'Doc10': [3]}],\n",
       " 'rush': [4, {'Doc7': [5], 'Doc8': [5], 'Doc9': [4], 'Doc10': [4]}],\n",
       " 'to': [4, {'Doc7': [6], 'Doc8': [6], 'Doc9': [5], 'Doc10': [5]}],\n",
       " 'tread': [4, {'Doc7': [7], 'Doc8': [7], 'Doc9': [6], 'Doc10': [6]}],\n",
       " 'where': [4, {'Doc7': [8], 'Doc8': [8], 'Doc9': [7], 'Doc10': [7]}]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positional_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prints the positional index, the tf.idf matrix normalized matrix, TF matrix, WTF matrix, df_idf and doc_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positional Index\n",
      "\n",
      "antony [3, {'Doc1': [1], 'Doc2': [1], 'Doc6': [1]}]\n",
      "brutus [3, {'Doc1': [2], 'Doc2': [2], 'Doc4': [1]}]\n",
      "caeser [5, {'Doc1': [3], 'Doc2': [3], 'Doc4': [2], 'Doc5': [1], 'Doc6': [2]}]\n",
      "cleopatra [1, {'Doc1': [4]}]\n",
      "mercy [5, {'Doc1': [5], 'Doc3': [1], 'Doc4': [3], 'Doc5': [2], 'Doc6': [3]}]\n",
      "worser [4, {'Doc1': [6], 'Doc3': [2], 'Doc4': [4], 'Doc5': [3]}]\n",
      "calpurnia [1, {'Doc2': [4]}]\n",
      "angels [3, {'Doc7': [1], 'Doc8': [1], 'Doc9': [1]}]\n",
      "fools [4, {'Doc7': [2], 'Doc8': [2], 'Doc9': [2], 'Doc10': [1]}]\n",
      "fear [3, {'Doc7': [3], 'Doc8': [3], 'Doc10': [2]}]\n",
      "in [4, {'Doc7': [4], 'Doc8': [4], 'Doc9': [3], 'Doc10': [3]}]\n",
      "rush [4, {'Doc7': [5], 'Doc8': [5], 'Doc9': [4], 'Doc10': [4]}]\n",
      "to [4, {'Doc7': [6], 'Doc8': [6], 'Doc9': [5], 'Doc10': [5]}]\n",
      "tread [4, {'Doc7': [7], 'Doc8': [7], 'Doc9': [6], 'Doc10': [6]}]\n",
      "where [4, {'Doc7': [8], 'Doc8': [8], 'Doc9': [7], 'Doc10': [7]}]\n",
      "----------------------------------------\n",
      "TF Matrix\n",
      "\n",
      "             Doc1    Doc2    Doc3    Doc4    Doc5    Doc6    Doc7    Doc8    Doc9    Doc10\n",
      "---------  ------  ------  ------  ------  ------  ------  ------  ------  ------  -------\n",
      "antony          1       1       0       0       0       1       0       0       0        0\n",
      "brutus          1       1       0       1       0       0       0       0       0        0\n",
      "caeser          1       1       0       1       1       1       0       0       0        0\n",
      "cleopatra       1       0       0       0       0       0       0       0       0        0\n",
      "mercy           1       0       1       1       1       1       0       0       0        0\n",
      "worser          1       0       1       1       1       0       0       0       0        0\n",
      "calpurnia       0       1       0       0       0       0       0       0       0        0\n",
      "angels          0       0       0       0       0       0       1       1       1        0\n",
      "fools           0       0       0       0       0       0       1       1       1        1\n",
      "fear            0       0       0       0       0       0       1       1       0        1\n",
      "in              0       0       0       0       0       0       1       1       1        1\n",
      "rush            0       0       0       0       0       0       1       1       1        1\n",
      "to              0       0       0       0       0       0       1       1       1        1\n",
      "tread           0       0       0       0       0       0       1       1       1        1\n",
      "where           0       0       0       0       0       0       1       1       1        1\n",
      "----------------------------------------\n",
      "w tf(1+ log tf) Matrix\n",
      "\n",
      "             Doc1    Doc2    Doc3    Doc4    Doc5    Doc6    Doc7    Doc8    Doc9    Doc10\n",
      "---------  ------  ------  ------  ------  ------  ------  ------  ------  ------  -------\n",
      "antony          1       1       0       0       0       1       0       0       0        0\n",
      "brutus          1       1       0       1       0       0       0       0       0        0\n",
      "caeser          1       1       0       1       1       1       0       0       0        0\n",
      "cleopatra       1       0       0       0       0       0       0       0       0        0\n",
      "mercy           1       0       1       1       1       1       0       0       0        0\n",
      "worser          1       0       1       1       1       0       0       0       0        0\n",
      "calpurnia       0       1       0       0       0       0       0       0       0        0\n",
      "angels          0       0       0       0       0       0       1       1       1        0\n",
      "fools           0       0       0       0       0       0       1       1       1        1\n",
      "fear            0       0       0       0       0       0       1       1       0        1\n",
      "in              0       0       0       0       0       0       1       1       1        1\n",
      "rush            0       0       0       0       0       0       1       1       1        1\n",
      "to              0       0       0       0       0       0       1       1       1        1\n",
      "tread           0       0       0       0       0       0       1       1       1        1\n",
      "where           0       0       0       0       0       0       1       1       1        1\n",
      "----------------------------------------\n",
      "df & idf Matrix\n",
      "\n",
      "             df       idf\n",
      "---------  ----  --------\n",
      "antony        3  0.522879\n",
      "brutus        3  0.522879\n",
      "caeser        5  0.30103\n",
      "cleopatra     1  1\n",
      "mercy         5  0.30103\n",
      "worser        4  0.39794\n",
      "calpurnia     1  1\n",
      "angels        3  0.522879\n",
      "fools         4  0.39794\n",
      "fear          3  0.522879\n",
      "in            4  0.39794\n",
      "rush          4  0.39794\n",
      "to            4  0.39794\n",
      "tread         4  0.39794\n",
      "where         4  0.39794\n",
      "----------------------------------------\n",
      "TF.IDF Matrix\n",
      "\n",
      "               Doc1      Doc2     Doc3      Doc4     Doc5      Doc6      Doc7      Doc8      Doc9     Doc10\n",
      "---------  --------  --------  -------  --------  -------  --------  --------  --------  --------  --------\n",
      "antony     0.522879  0.522879  0        0         0        0.522879  0         0         0         0\n",
      "brutus     0.522879  0.522879  0        0.522879  0        0         0         0         0         0\n",
      "caeser     0.30103   0.30103   0        0.30103   0.30103  0.30103   0         0         0         0\n",
      "cleopatra  1         0         0        0         0        0         0         0         0         0\n",
      "mercy      0.30103   0         0.30103  0.30103   0.30103  0.30103   0         0         0         0\n",
      "worser     0.39794   0         0.39794  0.39794   0.39794  0         0         0         0         0\n",
      "calpurnia  0         1         0        0         0        0         0         0         0         0\n",
      "angels     0         0         0        0         0        0         0.522879  0.522879  0.522879  0\n",
      "fools      0         0         0        0         0        0         0.39794   0.39794   0.39794   0.39794\n",
      "fear       0         0         0        0         0        0         0.522879  0.522879  0         0.522879\n",
      "in         0         0         0        0         0        0         0.39794   0.39794   0.39794   0.39794\n",
      "rush       0         0         0        0         0        0         0.39794   0.39794   0.39794   0.39794\n",
      "to         0         0         0        0         0        0         0.39794   0.39794   0.39794   0.39794\n",
      "tread      0         0         0        0         0        0         0.39794   0.39794   0.39794   0.39794\n",
      "where      0         0         0        0         0        0         0.39794   0.39794   0.39794   0.39794\n",
      "----------------------------------------\n",
      "Docs length Matrix\n",
      "\n",
      "         length\n",
      "-----  --------\n",
      "Doc1   1.37346\n",
      "Doc2   1.27962\n",
      "Doc3   0.498974\n",
      "Doc4   0.782941\n",
      "Doc5   0.582747\n",
      "Doc6   0.67427\n",
      "Doc7   1.2235\n",
      "Doc8   1.2235\n",
      "Doc9   1.10614\n",
      "Doc10  1.10614\n",
      "----------------------------------------\n",
      "Normalized tf.id\n",
      "\n",
      "               Doc1      Doc2      Doc3      Doc4      Doc5      Doc6      Doc7      Doc8      Doc9     Doc10\n",
      "---------  --------  --------  --------  --------  --------  --------  --------  --------  --------  --------\n",
      "antony     0.380701  0.408621  0         0         0         0.775474  0         0         0         0\n",
      "brutus     0.380701  0.408621  0         0.667839  0         0         0         0         0         0\n",
      "caeser     0.219176  0.23525   0         0.384486  0.51657   0.446453  0         0         0         0\n",
      "cleopatra  0.728087  0         0         0         0         0         0         0         0         0\n",
      "mercy      0.219176  0         0.603298  0.384486  0.51657   0.446453  0         0         0         0\n",
      "worser     0.289735  0         0.797516  0.508263  0.682869  0         0         0         0         0\n",
      "calpurnia  0         0.781483  0         0         0         0         0         0         0         0\n",
      "angels     0         0         0         0         0         0         0.427365  0.427365  0.472707  0\n",
      "fools      0         0         0         0         0         0         0.325248  0.325248  0.359756  0.359756\n",
      "fear       0         0         0         0         0         0         0.427365  0.427365  0         0.472707\n",
      "in         0         0         0         0         0         0         0.325248  0.325248  0.359756  0.359756\n",
      "rush       0         0         0         0         0         0         0.325248  0.325248  0.359756  0.359756\n",
      "to         0         0         0         0         0         0         0.325248  0.325248  0.359756  0.359756\n",
      "tread      0         0         0         0         0         0         0.325248  0.325248  0.359756  0.359756\n",
      "where      0         0         0         0         0         0         0.325248  0.325248  0.359756  0.359756\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "show_data(positional_index, tfidf_matrix, normalized_terms, tf_, wtf, df_idf, doc_lengths, numberOfDocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Matrix\n",
      "\n",
      "{'antony': {'Doc1': 1, 'Doc2': 1, 'Doc3': 0, 'Doc4': 0, 'Doc5': 0, 'Doc6': 1, 'Doc7': 0, 'Doc8': 0, 'Doc9': 0, 'Doc10': 0}, 'brutus': {'Doc1': 1, 'Doc2': 1, 'Doc3': 0, 'Doc4': 1, 'Doc5': 0, 'Doc6': 0, 'Doc7': 0, 'Doc8': 0, 'Doc9': 0, 'Doc10': 0}, 'caeser': {'Doc1': 1, 'Doc2': 1, 'Doc3': 0, 'Doc4': 1, 'Doc5': 1, 'Doc6': 1, 'Doc7': 0, 'Doc8': 0, 'Doc9': 0, 'Doc10': 0}, 'cleopatra': {'Doc1': 1, 'Doc2': 0, 'Doc3': 0, 'Doc4': 0, 'Doc5': 0, 'Doc6': 0, 'Doc7': 0, 'Doc8': 0, 'Doc9': 0, 'Doc10': 0}, 'mercy': {'Doc1': 1, 'Doc2': 0, 'Doc3': 1, 'Doc4': 1, 'Doc5': 1, 'Doc6': 1, 'Doc7': 0, 'Doc8': 0, 'Doc9': 0, 'Doc10': 0}, 'worser': {'Doc1': 1, 'Doc2': 0, 'Doc3': 1, 'Doc4': 1, 'Doc5': 1, 'Doc6': 0, 'Doc7': 0, 'Doc8': 0, 'Doc9': 0, 'Doc10': 0}, 'calpurnia': {'Doc1': 0, 'Doc2': 1, 'Doc3': 0, 'Doc4': 0, 'Doc5': 0, 'Doc6': 0, 'Doc7': 0, 'Doc8': 0, 'Doc9': 0, 'Doc10': 0}, 'angels': {'Doc1': 0, 'Doc2': 0, 'Doc3': 0, 'Doc4': 0, 'Doc5': 0, 'Doc6': 0, 'Doc7': 1, 'Doc8': 1, 'Doc9': 1, 'Doc10': 0}, 'fools': {'Doc1': 0, 'Doc2': 0, 'Doc3': 0, 'Doc4': 0, 'Doc5': 0, 'Doc6': 0, 'Doc7': 1, 'Doc8': 1, 'Doc9': 1, 'Doc10': 1}, 'fear': {'Doc1': 0, 'Doc2': 0, 'Doc3': 0, 'Doc4': 0, 'Doc5': 0, 'Doc6': 0, 'Doc7': 1, 'Doc8': 1, 'Doc9': 0, 'Doc10': 1}, 'in': {'Doc1': 0, 'Doc2': 0, 'Doc3': 0, 'Doc4': 0, 'Doc5': 0, 'Doc6': 0, 'Doc7': 1, 'Doc8': 1, 'Doc9': 1, 'Doc10': 1}, 'rush': {'Doc1': 0, 'Doc2': 0, 'Doc3': 0, 'Doc4': 0, 'Doc5': 0, 'Doc6': 0, 'Doc7': 1, 'Doc8': 1, 'Doc9': 1, 'Doc10': 1}, 'to': {'Doc1': 0, 'Doc2': 0, 'Doc3': 0, 'Doc4': 0, 'Doc5': 0, 'Doc6': 0, 'Doc7': 1, 'Doc8': 1, 'Doc9': 1, 'Doc10': 1}, 'tread': {'Doc1': 0, 'Doc2': 0, 'Doc3': 0, 'Doc4': 0, 'Doc5': 0, 'Doc6': 0, 'Doc7': 1, 'Doc8': 1, 'Doc9': 1, 'Doc10': 1}, 'where': {'Doc1': 0, 'Doc2': 0, 'Doc3': 0, 'Doc4': 0, 'Doc5': 0, 'Doc6': 0, 'Doc7': 1, 'Doc8': 1, 'Doc9': 1, 'Doc10': 1}}\n",
      "\n",
      "w tf(1+ log tf) Matrix\n",
      "\n",
      "{'antony': {'Doc1': 1.0, 'Doc2': 1.0, 'Doc3': 0.0, 'Doc4': 0.0, 'Doc5': 0.0, 'Doc6': 1.0, 'Doc7': 0.0, 'Doc8': 0.0, 'Doc9': 0.0, 'Doc10': 0.0}, 'brutus': {'Doc1': 1.0, 'Doc2': 1.0, 'Doc3': 0.0, 'Doc4': 1.0, 'Doc5': 0.0, 'Doc6': 0.0, 'Doc7': 0.0, 'Doc8': 0.0, 'Doc9': 0.0, 'Doc10': 0.0}, 'caeser': {'Doc1': 1.0, 'Doc2': 1.0, 'Doc3': 0.0, 'Doc4': 1.0, 'Doc5': 1.0, 'Doc6': 1.0, 'Doc7': 0.0, 'Doc8': 0.0, 'Doc9': 0.0, 'Doc10': 0.0}, 'cleopatra': {'Doc1': 1.0, 'Doc2': 0.0, 'Doc3': 0.0, 'Doc4': 0.0, 'Doc5': 0.0, 'Doc6': 0.0, 'Doc7': 0.0, 'Doc8': 0.0, 'Doc9': 0.0, 'Doc10': 0.0}, 'mercy': {'Doc1': 1.0, 'Doc2': 0.0, 'Doc3': 1.0, 'Doc4': 1.0, 'Doc5': 1.0, 'Doc6': 1.0, 'Doc7': 0.0, 'Doc8': 0.0, 'Doc9': 0.0, 'Doc10': 0.0}, 'worser': {'Doc1': 1.0, 'Doc2': 0.0, 'Doc3': 1.0, 'Doc4': 1.0, 'Doc5': 1.0, 'Doc6': 0.0, 'Doc7': 0.0, 'Doc8': 0.0, 'Doc9': 0.0, 'Doc10': 0.0}, 'calpurnia': {'Doc1': 0.0, 'Doc2': 1.0, 'Doc3': 0.0, 'Doc4': 0.0, 'Doc5': 0.0, 'Doc6': 0.0, 'Doc7': 0.0, 'Doc8': 0.0, 'Doc9': 0.0, 'Doc10': 0.0}, 'angels': {'Doc1': 0.0, 'Doc2': 0.0, 'Doc3': 0.0, 'Doc4': 0.0, 'Doc5': 0.0, 'Doc6': 0.0, 'Doc7': 1.0, 'Doc8': 1.0, 'Doc9': 1.0, 'Doc10': 0.0}, 'fools': {'Doc1': 0.0, 'Doc2': 0.0, 'Doc3': 0.0, 'Doc4': 0.0, 'Doc5': 0.0, 'Doc6': 0.0, 'Doc7': 1.0, 'Doc8': 1.0, 'Doc9': 1.0, 'Doc10': 1.0}, 'fear': {'Doc1': 0.0, 'Doc2': 0.0, 'Doc3': 0.0, 'Doc4': 0.0, 'Doc5': 0.0, 'Doc6': 0.0, 'Doc7': 1.0, 'Doc8': 1.0, 'Doc9': 0.0, 'Doc10': 1.0}, 'in': {'Doc1': 0.0, 'Doc2': 0.0, 'Doc3': 0.0, 'Doc4': 0.0, 'Doc5': 0.0, 'Doc6': 0.0, 'Doc7': 1.0, 'Doc8': 1.0, 'Doc9': 1.0, 'Doc10': 1.0}, 'rush': {'Doc1': 0.0, 'Doc2': 0.0, 'Doc3': 0.0, 'Doc4': 0.0, 'Doc5': 0.0, 'Doc6': 0.0, 'Doc7': 1.0, 'Doc8': 1.0, 'Doc9': 1.0, 'Doc10': 1.0}, 'to': {'Doc1': 0.0, 'Doc2': 0.0, 'Doc3': 0.0, 'Doc4': 0.0, 'Doc5': 0.0, 'Doc6': 0.0, 'Doc7': 1.0, 'Doc8': 1.0, 'Doc9': 1.0, 'Doc10': 1.0}, 'tread': {'Doc1': 0.0, 'Doc2': 0.0, 'Doc3': 0.0, 'Doc4': 0.0, 'Doc5': 0.0, 'Doc6': 0.0, 'Doc7': 1.0, 'Doc8': 1.0, 'Doc9': 1.0, 'Doc10': 1.0}, 'where': {'Doc1': 0.0, 'Doc2': 0.0, 'Doc3': 0.0, 'Doc4': 0.0, 'Doc5': 0.0, 'Doc6': 0.0, 'Doc7': 1.0, 'Doc8': 1.0, 'Doc9': 1.0, 'Doc10': 1.0}}\n",
      "\n",
      "df & idf Matrix\n",
      "\n",
      "{'antony': {'df': 3, 'idf': 0.5228787453}, 'brutus': {'df': 3, 'idf': 0.5228787453}, 'caeser': {'df': 5, 'idf': 0.3010299957}, 'cleopatra': {'df': 1, 'idf': 1.0}, 'mercy': {'df': 5, 'idf': 0.3010299957}, 'worser': {'df': 4, 'idf': 0.3979400087}, 'calpurnia': {'df': 1, 'idf': 1.0}, 'angels': {'df': 3, 'idf': 0.5228787453}, 'fools': {'df': 4, 'idf': 0.3979400087}, 'fear': {'df': 3, 'idf': 0.5228787453}, 'in': {'df': 4, 'idf': 0.3979400087}, 'rush': {'df': 4, 'idf': 0.3979400087}, 'to': {'df': 4, 'idf': 0.3979400087}, 'tread': {'df': 4, 'idf': 0.3979400087}, 'where': {'df': 4, 'idf': 0.3979400087}}\n",
      "\n",
      "TF.IDF Matrix\n",
      "\n",
      "{'antony': [0.5228787453, 0.5228787453, 0.0, 0.0, 0.0, 0.5228787453, 0.0, 0.0, 0.0, 0.0], 'brutus': [0.5228787453, 0.5228787453, 0.0, 0.5228787453, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'caeser': [0.3010299957, 0.3010299957, 0.0, 0.3010299957, 0.3010299957, 0.3010299957, 0.0, 0.0, 0.0, 0.0], 'cleopatra': [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'mercy': [0.3010299957, 0.0, 0.3010299957, 0.3010299957, 0.3010299957, 0.3010299957, 0.0, 0.0, 0.0, 0.0], 'worser': [0.3979400087, 0.0, 0.3979400087, 0.3979400087, 0.3979400087, 0.0, 0.0, 0.0, 0.0, 0.0], 'calpurnia': [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'angels': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5228787453, 0.5228787453, 0.5228787453, 0.0], 'fools': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3979400087, 0.3979400087, 0.3979400087, 0.3979400087], 'fear': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5228787453, 0.5228787453, 0.0, 0.5228787453], 'in': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3979400087, 0.3979400087, 0.3979400087, 0.3979400087], 'rush': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3979400087, 0.3979400087, 0.3979400087, 0.3979400087], 'to': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3979400087, 0.3979400087, 0.3979400087, 0.3979400087], 'tread': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3979400087, 0.3979400087, 0.3979400087, 0.3979400087], 'where': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3979400087, 0.3979400087, 0.3979400087, 0.3979400087]}\n",
      "\n",
      "Docs length Matrix\n",
      "\n",
      "[1.373462315, 1.279618468, 0.498974257, 0.782940962, 0.582747258, 0.674270197, 1.223495757, 1.223495757, 1.106137281, 1.106137281]\n",
      "\n",
      "Normalized tf.id\n",
      "\n",
      "{'antony': [0.3807011955, 0.4086208181, 0.0, 0.0, 0.0, 0.7754736122, 0.0, 0.0, 0.0, 0.0], 'brutus': [0.3807011955, 0.4086208181, 0.0, 0.6678393017, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'caeser': [0.2191760141, 0.2352498055, 0.0, 0.3844862005, 0.5165704198, 0.4464530644, 0.0, 0.0, 0.0, 0.0], 'cleopatra': [0.7280869588, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'mercy': [0.2191760141, 0.0, 0.6032976481, 0.3844862005, 0.5165704198, 0.4464530644, 0.0, 0.0, 0.0, 0.0], 'worser': [0.2897349307, 0.0, 0.7975161105, 0.5082631105, 0.6828689509, 0.0, 0.0, 0.0, 0.0, 0.0], 'calpurnia': [0.0, 0.7814829381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'angels': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4273645759, 0.4273645759, 0.4727069183, 0.0], 'fools': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3252483766, 0.3252483766, 0.3597564385, 0.3597564385], 'fear': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4273645759, 0.4273645759, 0.0, 0.4727069183], 'in': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3252483766, 0.3252483766, 0.3597564385, 0.3597564385], 'rush': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3252483766, 0.3252483766, 0.3597564385, 0.3597564385], 'to': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3252483766, 0.3252483766, 0.3597564385, 0.3597564385], 'tread': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3252483766, 0.3252483766, 0.3597564385, 0.3597564385], 'where': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3252483766, 0.3252483766, 0.3597564385, 0.3597564385]}\n"
     ]
    }
   ],
   "source": [
    "print(\"TF Matrix\")\n",
    "print()\n",
    "print(tf_)\n",
    "print()\n",
    "print(\"w tf(1+ log tf) Matrix\")\n",
    "print()\n",
    "print(wtf)\n",
    "print()\n",
    "print(\"df & idf Matrix\")\n",
    "print()\n",
    "print(df_idf)\n",
    "print()\n",
    "print(\"TF.IDF Matrix\")\n",
    "print()\n",
    "print(tfidf_matrix)\n",
    "print()\n",
    "print(\"Docs length Matrix\")\n",
    "print()\n",
    "print(doc_lengths)\n",
    "print()\n",
    "print(\"Normalized tf.id\")\n",
    "print()\n",
    "print(normalized_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your search query:\n",
      "antony brutus\n",
      "\n",
      "\n",
      "          tf-raw\n",
      "------  --------\n",
      "antony         1\n",
      "brutus         1\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "          w tf(1+ log tf)\n",
      "------  -----------------\n",
      "antony                  1\n",
      "brutus                  1\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "             idf\n",
      "------  --------\n",
      "antony  0.522879\n",
      "brutus  0.522879\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "          tf*idf\n",
      "------  --------\n",
      "antony  0.522879\n",
      "brutus  0.522879\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "          normalized\n",
      "------  ------------\n",
      "antony      0.707107\n",
      "brutus      0.707107\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "        antony    brutus       SUM\n",
      "----  --------  --------  --------\n",
      "Doc1  0.269196  0.269196  0.538393\n",
      "Doc2  0.288939  0.288939  0.577877\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "query length 0.7394622130798872\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "  Search results ranked\n",
      "\n",
      "1. Document name: Doc2\n",
      "   Cosine similarity: 0.578\n",
      "\n",
      "2. Document name: Doc1\n",
      "   Cosine similarity: 0.538\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = input(\"Enter your search query:\\n\")\n",
    "ranked_results, query_normalized, rtf,tf, length, tfidf, idf, product = engine(query, positional_index, tfidf_matrix, doc_lengths, numberOfDocs)\n",
    "if ranked_results == {}:\n",
    "    print(\"There are no matching documents for your search query\")\n",
    "else:\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(tabulate(prepareToPrint(rtf), headers=[\" \",\"tf-raw\"]))\n",
    "    print(\"\")\n",
    "    print(\"----------------------------------------\")\n",
    "    print(\"\")\n",
    "    print(tabulate(prepareToPrint(tf), headers=[\" \",\"w tf(1+ log tf)\"]))\n",
    "    print(\"\")\n",
    "    print(\"----------------------------------------\")\n",
    "    print(\"\")\n",
    "    print(tabulate(prepareToPrint(idf), headers=[\" \",\"idf\"]))\n",
    "    print(\"\")\n",
    "    print(\"----------------------------------------\")\n",
    "    print(\"\")\n",
    "    print(tabulate(prepareToPrint(tfidf), headers=[\" \",\"tf*idf\"]))\n",
    "    print(\"\")\n",
    "    print(\"----------------------------------------\")\n",
    "    print(\"\")\n",
    "    print(tabulate(prepareToPrint(query_normalized), headers=[\" \",\"normalized\"]))\n",
    "    print(\"\")\n",
    "    print(\"----------------------------------------\")\n",
    "    print(\"\")\n",
    "    print(tabulate(prepareToPrint(product), headers=list(list(product.values())[0].keys())))\n",
    "    print(\"\")\n",
    "    print(\"----------------------------------------\")\n",
    "    print(\"\")\n",
    "    print('query length', length)\n",
    "    print(\"\")\n",
    "    print(\"----------------------------------------\")\n",
    "    print(\"\")\n",
    "    print(\"  Search results ranked\\n\")\n",
    "    i = 1\n",
    "    for result in ranked_results:\n",
    "        print(str(i) + \".\" + \" Document name: \" + str(result) + \"\\n   Cosine similarity: \"\n",
    "              + str(round(ranked_results[result], 3)) + \"\\n\")\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1741790972.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_16656\\1741790972.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    antony brutus\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "antony brutus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#antony brutus caeser cleopatra mercy worser"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
